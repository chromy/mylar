#!/usr/bin/env python3

import argparse
import glob
import os
import re
import sys
import subprocess
from pathlib import Path

ROOT_DIR = os.path.dirname(os.path.abspath(__file__))

def is_target(path):
  return path.endswith(b"tsconfig.json") or path.endswith(b".ts") or path.endswith(b".tsx")


def parse_args(text):
  i = 0

  def eat_literal(c):
    nonlocal i
    assert i < len(text) and text[i] == c
    i += 1

  def eat_spaces():
    nonlocal i
    while i < len(text) and text[i] == " ":
      i += 1

  def eat_key():
    nonlocal i
    start = i
    while i < len(text) and text[i] != "=":
      i += 1
    end = i

    key = text[start:end]

    return key

  def eat_value():
    nonlocal i
    eat_literal("\"")

    start = i
    while i < len(text) and text[i] != "\"":
      if text[i:].startswith("\\\""):
        i += 2
      else:
        i += 1
    end = i

    eat_literal("\"")

    value = text[start:end].replace("\\\"", "\"")
    return value

  args = {}
  while i < len(text):
    key = eat_key()
    eat_literal("=")
    value = eat_value()
    eat_spaces()
    args[key] = value
  return args



def find_globby_patterns(content, file_path):
  """Find all GLOBBY_START/GLOBBY_END patterns in the content."""
  lines = content.split("\n")
  patterns = []
  i = 0

  while i < len(lines):
    line = lines[i]
    start_match = re.search(r"//\s*GLOBBY_START\s+(\S+) ?(.*)$", line)

    if start_match:
      pattern = start_match.group(1).strip()
      raw_args = start_match.group(2).strip()
      start_line = i
      end_line = -1

      args = parse_args(raw_args)

      ext = args.get("ext", "")
      prefix = args.get("prefix", "\"")
      suffix = args.get("suffix", "\"")
      comma = args.get("comma", ",")

      # Find the corresponding GLOBBY_END
      for j in range(i + 1, len(lines)):
        if re.search(r"//\s*GLOBBY_END", lines[j]):
          end_line = j
          break

      if end_line == -1:
        print(f"Error in {path}: GLOBBY_START at line {start_line + 1} has no matching GLOBBY_END", file=sys.stderr)
        sys.exit(1)

      patterns.append({
        "pattern": pattern,
        "start_line": start_line,
        "end_line": end_line,
        "current_content": lines[start_line + 1:end_line],
        "ext": ext,
        "prefix": prefix,
        "suffix": suffix,
        "comma": comma,
      })

      i = end_line + 1
    else:
      i += 1

  return patterns


def get_glob_matches(pattern, base_dir):
  """Get files matching the glob pattern."""
  try:
    # Change to base directory for glob matching, handle empty base_dir
    if not base_dir:
      base_dir = "."
    old_cwd = os.getcwd()
    os.chdir(base_dir)
    matches = glob.glob(pattern, recursive=True)
    os.chdir(old_cwd)
    return sorted(matches)
  except Exception as e:
    print(f"Error executing glob pattern \"{pattern}\": {e}", file=sys.stderr)
    sys.exit(1)


def process_file(path, check_mode=False):
  """Process a single file for globby patterns."""
  try:
    with open(path, "r", encoding="utf-8") as f:
      content = f.read()
  except Exception as e:
    print(f"Error reading {path}: {e}", file=sys.stderr)
    return {"has_changes": False}

  patterns = find_globby_patterns(content, path)

  if not patterns:
    return {"has_changes": False}

  lines = content.split("\n")
  has_changes = False

  # Process patterns in reverse order to maintain line numbers
  for pattern_info in reversed(patterns):
    pattern = pattern_info["pattern"]
    start_line = pattern_info["start_line"]
    end_line = pattern_info["end_line"]
    current_content = pattern_info["current_content"]
    comma = pattern_info["comma"]
    prefix = pattern_info["prefix"]
    suffix = pattern_info["suffix"]
    ext = pattern_info["ext"]

    base_dir = os.path.dirname(path)
    files = get_glob_matches(pattern, base_dir)
    if ext:
      files = [file.split(".")[0] + f".{ext}" for file in files]

    # Detect indentation from the start line
    start_line_content = lines[start_line]
    indent_match = re.match(r"^(\s*)", start_line_content)
    indentation = indent_match.group(1) if indent_match else "  "

    expected_lines = [f"{indentation}{prefix}{file}{suffix}" for file in files]
    expected_lines.sort()

    current = "\n".join(current_content)

    expected = f"{comma}\n".join(expected_lines)

    if current != expected:
      has_changes = True

      if check_mode:
        print(f"File {path} is out of sync:", file=sys.stderr)
        print(f"  Pattern: {pattern}", file=sys.stderr)
        print(f"  Expected {len(expected)} files, found {len(current)}", file=sys.stderr)
        return {"has_changes": True}
      else:
        # Replace the content between GLOBBY_START and GLOBBY_END
        lines[start_line + 1:end_line] = [expected]

  if has_changes and not check_mode:
    try:
      with open(path, "w", encoding="utf-8") as f:
        f.write("\n".join(lines))
      print(f"Updated {path}")
    except Exception as e:
      print(f"Error writing {path}: {e}", file=sys.stderr)
      return {"has_changes": False}

  return {"has_changes": has_changes}


def main():
  parser = argparse.ArgumentParser(
    description="Keep file lists in sync using glob patterns.",
    formatter_class=argparse.RawDescriptionHelpFormatter,
    epilog="""
Examples:
  %(prog)s tsconfig.json        # Fix all globby sections in tsconfig.json
  %(prog)s --check **/*.json      # Check all JSON files

The script looks for comments like:
  // GLOBBY_START pattern
  // GLOBBY_END

And replaces the content between them with files matching the glob pattern.
    """
  )

  parser.add_argument("--check", action="store_true",
             help="Only check if files are in sync, don\'t modify")

  args = parser.parse_args()

  output = subprocess.check_output([
    "git",
    "ls-tree",
    "-r",
    "HEAD",
    "--full-name",
    "-z",
    ROOT_DIR
  ])

  lines = output.split(b"\0")
  paths = [line.split(b"\t", 1)[1] for line in lines if line]
  paths = [path for path in paths if is_target(path)]

  has_any_changes = False

  for path in paths:
    if not os.path.exists(path):
      print(f"Error: File {path} does not exist", file=sys.stderr)
      continue

    result = process_file(path, args.check)
    if result["has_changes"]:
      has_any_changes = True

  if args.check and has_any_changes:
    print("Some files are out of sync. Run without --check to fix them.", file=sys.stderr)
    sys.exit(1)


if __name__ == "__main__":
  main()
